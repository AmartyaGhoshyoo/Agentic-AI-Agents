{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4cacbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent,ModelSettings, function_tool,Runner\n",
    "@function_tool\n",
    "def get_weather(city:str)->str:\n",
    "    return f'The weather in the {city} is sunny'\n",
    "\n",
    "agent=Agent(\n",
    "    name=\"Haiku Agent\",\n",
    "    instructions=\"Always respond in haiku form\",\n",
    "    model='gpt-4.1-mini',\n",
    "    tools=[get_weather]\n",
    ")\n",
    "async def main():\n",
    "    result=await Runner.run(agent, \"Tell me weather in chittagong\")\n",
    "    # print(dir(result))\n",
    "    # print(result.final_output )\n",
    "    return result\n",
    "# if __name__=='__main__':\n",
    "#     import asyncio\n",
    "#     # asyncio.run(main())\n",
    "#     await main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "759b2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f0e4eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(input='Tell me weather in chittagong', new_items=[ToolCallItem(agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10f408fe0>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"city\":\"Chittagong\"}', call_id='call_1w9NaJkAWTcEqu6wEWn1VIi4', name='get_weather', type='function_call', id='fc_68d134dc8f8c819598a77bb091ce04200ea102927129918d', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10f408fe0>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_1w9NaJkAWTcEqu6wEWn1VIi4', 'output': 'The weather in the Chittagong is sunny', 'type': 'function_call_output'}, output='The weather in the Chittagong is sunny', type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10f408fe0>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_68d134de6b248195be6ef2bc2576bf1a0ea102927129918d', content=[ResponseOutputText(annotations=[], text='Chittagong sun shines,  \\nGolden rays warm the soft breeze,  \\nBright day in the port.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"city\":\"Chittagong\"}', call_id='call_1w9NaJkAWTcEqu6wEWn1VIi4', name='get_weather', type='function_call', id='fc_68d134dc8f8c819598a77bb091ce04200ea102927129918d', status='completed')], usage=Usage(requests=1, input_tokens=57, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=18, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=75), response_id='resp_68d134db999c8195ab11c699fcf4c9a60ea102927129918d'), ModelResponse(output=[ResponseOutputMessage(id='msg_68d134de6b248195be6ef2bc2576bf1a0ea102927129918d', content=[ResponseOutputText(annotations=[], text='Chittagong sun shines,  \\nGolden rays warm the soft breeze,  \\nBright day in the port.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=93, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=24, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=117), response_id='resp_68d134ddc928819589a9d4c878fa01310ea102927129918d')], final_output='Chittagong sun shines,  \\nGolden rays warm the soft breeze,  \\nBright day in the port.', input_guardrail_results=[], output_guardrail_results=[], context_wrapper=RunContextWrapper(context=None, usage=Usage(requests=2, input_tokens=150, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=42, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=192)), _last_agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10f408fe0>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc483a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_call_item\n",
      "tool_call_output_item\n",
      "message_output_item\n",
      "Chittagong sun shines,  \n",
      "Golden rays warm the soft breeze,  \n",
      "Bright day in the port.\n"
     ]
    }
   ],
   "source": [
    "from agents import ItemHelpers, MessageOutputItem\n",
    "\n",
    "\n",
    "for item in result.new_items:\n",
    "    print(item.type)\n",
    "    # print(item.raw_item)\n",
    "    if isinstance(item,MessageOutputItem):\n",
    "        text=ItemHelpers.text_message_output(item)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08301465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_last_agent', 'context_wrapper', 'final_output', 'final_output_as', 'input', 'input_guardrail_results', 'last_agent', 'last_response_id', 'new_items', 'output_guardrail_results', 'raw_responses', 'to_input_list']\n",
      "Visionary mind,  \n",
      "Built a world with software keys,  \n",
      "Gates opens new paths.\n"
     ]
    }
   ],
   "source": [
    "result=await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a70257e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(input='Tell me about bill gates', new_items=[MessageOutputItem(agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10edcd080>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_68d132f0ac0c81a3b6f734f4caddcfe9009f05a6b5b692f9', content=[ResponseOutputText(annotations=[], text='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseOutputMessage(id='msg_68d132f0ac0c81a3b6f734f4caddcfe9009f05a6b5b692f9', content=[ResponseOutputText(annotations=[], text='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=54, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=21, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=75), response_id='resp_68d132f0597081a3947a413b36059ac6009f05a6b5b692f9')], final_output='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', input_guardrail_results=[], output_guardrail_results=[], context_wrapper=RunContextWrapper(context=None, usage=Usage(requests=1, input_tokens=54, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=21, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=75)), _last_agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10edcd080>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65314e95",
   "metadata": {},
   "source": [
    "RunResult(input='Tell me about bill gates', new_items=[MessageOutputItem(agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10edcd080>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_68d132f0ac0c81a3b6f734f4caddcfe9009f05a6b5b692f9', content=[ResponseOutputText(annotations=[], text='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseOutputMessage(id='msg_68d132f0ac0c81a3b6f734f4caddcfe9009f05a6b5b692f9', content=[ResponseOutputText(annotations=[], text='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=54, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=21, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=75), response_id='resp_68d132f0597081a3947a413b36059ac6009f05a6b5b692f9')], final_output='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', input_guardrail_results=[], output_guardrail_results=[], context_wrapper=RunContextWrapper(context=None, usage=Usage(requests=1, input_tokens=54, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=21, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=75)), _last_agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10edcd080>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee89d0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about bill gates',\n",
       " 'new_items': [MessageOutputItem(agent=Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10edcd080>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_68d132f0ac0c81a3b6f734f4caddcfe9009f05a6b5b692f9', content=[ResponseOutputText(annotations=[], text='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), type='message_output_item')],\n",
       " 'raw_responses': [ModelResponse(output=[ResponseOutputMessage(id='msg_68d132f0ac0c81a3b6f734f4caddcfe9009f05a6b5b692f9', content=[ResponseOutputText(annotations=[], text='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=54, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=21, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=75), response_id='resp_68d132f0597081a3947a413b36059ac6009f05a6b5b692f9')],\n",
       " 'final_output': 'Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.',\n",
       " 'input_guardrail_results': [],\n",
       " 'output_guardrail_results': [],\n",
       " 'context_wrapper': RunContextWrapper(context=None, usage=Usage(requests=1, input_tokens=54, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=21, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=75)),\n",
       " '_last_agent': Agent(name='Haiku Agent', handoff_description=None, tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10edcd080>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, instructions='Always respond in haiku form', prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59781cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import ItemHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b48b836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message_output_item\n",
      "ResponseOutputMessage(id='msg_68d132f0ac0c81a3b6f734f4caddcfe9009f05a6b5b692f9', content=[ResponseOutputText(annotations=[], text='Visionary mind,  \\nBuilt a world with software keys,  \\nGates opens new paths.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')\n",
      "Visionary mind,  \n",
      "Built a world with software keys,  \n",
      "Gates opens new paths.\n"
     ]
    }
   ],
   "source": [
    "from agents import ItemHelpers, MessageOutputItem\n",
    "\n",
    "\n",
    "for item in result.new_items:\n",
    "    print(item.type)\n",
    "    print(item.raw_item)\n",
    "    if isinstance(item,MessageOutputItem):\n",
    "        text=ItemHelpers.text_message_output(item)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf7bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
